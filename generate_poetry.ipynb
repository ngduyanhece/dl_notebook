{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import theano\n",
    "import theano.tensor as T\n",
    "import numpy as np\n",
    "import string\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import shuffle\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def remove_punctuation(s):\n",
    "    return s.translate(None, string.punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def init_weight(mi,mo):\n",
    "    return np.random.randn(mi,mo) / np.sqrt(mi+mo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_robert_frost():\n",
    "    word2idx = {'START': 0, 'END': 1}\n",
    "    current_idx = 2\n",
    "    sentences = []\n",
    "    for line in open('../data/robert_frost.txt'):\n",
    "        line = line.strip()\n",
    "        if line:\n",
    "            tokens = remove_punctuation(line.lower()).split()\n",
    "            sentence = []\n",
    "            for t in tokens:\n",
    "                if t not in word2idx:\n",
    "                    word2idx[t] = current_idx\n",
    "                    current_idx += 1\n",
    "                idx = word2idx[t]\n",
    "                sentence.append(idx)\n",
    "            sentences.append(sentence)\n",
    "    return sentences,word2idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class SimpleRNN(object):\n",
    "    def __init__(self,D,M,V):\n",
    "        self.D = D # dimensionality of word embedding \n",
    "        self.M = M # hidden layer size \n",
    "        self.V = V # vocabulary size\n",
    "    def train(self, X, learning_rate=10e-1, mu=0.99, reg=1.0, epochs=500, show_fig=False):\n",
    "        N = len(X)\n",
    "        D = self.D\n",
    "        M = self.M \n",
    "        V = self.V\n",
    "        #init weights \n",
    "        We = init_weight(V,D)\n",
    "        Wx = init_weight(D,M)\n",
    "        Wh = init_weight(M,M)\n",
    "        bh = np.zeros(M)\n",
    "        h0 = np.zeros(M)\n",
    "        Wo = init_weight(M,V)\n",
    "        bo = np.zeros(V)\n",
    "        #make them theano shared \n",
    "        self.We = theano.shared(We)\n",
    "        self.Wx = theano.shared(Wx)\n",
    "        self.Wh = theano.shared(Wh)\n",
    "        self.bh = theano.shared(bh)\n",
    "        self.h0 = theano.shared(h0)\n",
    "        self.Wo = theano.shared(Wo)\n",
    "        self.bo = theano.shared(bo)\n",
    "        self.params = [self.We,self.Wx,self.Wh,self.bh,self.h0,self.Wo,self.bo]\n",
    "        thX = T.ivector('X')\n",
    "        Ei = self.We[thX]\n",
    "        thY = T.ivector('Y')\n",
    "        \n",
    "        def recurrence(x_t,h_t1):\n",
    "            h_t = T.nnet.relu(x_t.dot(self.Wx) + h_t1.dot(self.Wh) + bh)\n",
    "            y_t = T.nnet.softmax(h_t.dot(self.Wo) + self.bo)\n",
    "            return h_t,y_t\n",
    "        [h,y],_ = theano.scan(\n",
    "            fn = recurrence,\n",
    "            outputs_info = [self.h0,None],\n",
    "            sequences = Ei,\n",
    "            n_steps = Ei.shape[0],\n",
    "        )\n",
    "        py_x = y[:, 0, :]\n",
    "        prediction = T.argmax(py_x, axis=1)\n",
    "        cost = -T.mean(T.log(py_x[T.arange(thY.shape[0]), thY]))\n",
    "        grads = T.grad(cost, self.params)\n",
    "        dparams = [theano.shared(p.get_value()*0) for p in self.params]\n",
    "        updates = [\n",
    "            (p, p + mu*dp - learning_rate*g) for p, dp, g in zip(self.params, dparams, grads)\n",
    "        ] + [\n",
    "            (dp, mu*dp - learning_rate*g) for dp, g in zip(dparams, grads)\n",
    "        ]\n",
    "        self.predict_op = theano.function(inputs=[thX], outputs=prediction)\n",
    "        self.train_op = theano.function(\n",
    "            inputs=[thX, thY],\n",
    "            outputs=[cost, prediction],\n",
    "            updates=updates\n",
    "        )\n",
    "        costs = []\n",
    "        n_total = sum((len(sentence)+1) for sentence in X)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
